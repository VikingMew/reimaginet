{
 "metadata": {
  "name": "",
  "signature": "sha256:e7767ddf00900cd45571fe0e5e8198a299b442e4bdc0819eb8db59c7a476c3c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import imaginet.task as task\n",
      "import imaginet.defn.audiovis_rhn as audiovis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5005)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load two models:\n",
      "- RHN model on flickr8K human speech, with MFCC features + first and second differences (`mfcc_accel`)\n",
      "- RHN model on coco synthetic speech, with plain MFCC features (`mfcc`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_f = task.load(\"/home/gchrupala/reimaginet/examples/audioviz/human-mfcc-rhn-flickr8k.zip\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_c = task.load(\"/home/gchrupala/reimaginet/run-rhn-coco-8/model.r.e4.zip\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Synthesize speech\n",
      "\n",
      "### Read MEN data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_men():\n",
      "    records = []\n",
      "    for line in open(\"/home/gchrupala/reimaginet/data/MEN/MEN_dataset_natural_form_full\"):\n",
      "        word1, word2, score = line.split()\n",
      "        records.append((word1, word2, float(score)))\n",
      "    return records\n",
      "MEN = read_men()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Synthesize speech for all the words in MEN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import imaginet.tts as tts\n",
      "\n",
      "def synthesize(text):\n",
      "    return tts.decodemp3(tts.speak(text))\n",
      "\n",
      "def speak(data):\n",
      "    voc = set()\n",
      "    for (w1,w2,_) in data:\n",
      "        voc.add(w1)\n",
      "        voc.add(w2)\n",
      "    voc = list(voc)\n",
      "    speech = [ synthesize(word) for word in voc ]\n",
      "    return (voc, speech)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Synthesize speech"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Synthesize and save for reuse.\n",
      "This is slow, so we'll comment it out and use pre-synthesize speech"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# voc_men, speech_men = speak(MEN)\n",
      "#\n",
      "\n",
      "# pickle.dump(voc_men, open(\"/home/gchrupala/reimaginet/data/MEN/voc.pkl\",\"w\"),\n",
      "#            protocol=pickle.HIGHEST_PROTOCOL)\n",
      "# pickle.dump(speech_men, open(\"/home/gchrupala/reimaginet/data/MEN/speech.pkl\",\"w\"),\n",
      "#            protocol=pickle.HIGHEST_PROTOCOL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "voc_men = pickle.load(open(\"/home/gchrupala/reimaginet/data/MEN/voc.pkl\"))\n",
      "speech_men = pickle.load(open(\"/home/gchrupala/reimaginet/data/MEN/speech.pkl\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extract `mfcc` and `mfcc_accel` features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mfcc_men = [ tts.extract_mfcc(audio) for audio in speech_men ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mfcc_accel_men = tts.add_accel(mfcc_men)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mfcc_men[1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "(69, 13)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`mfcc_accel` adds first order and second order differences, or rate or change and acceleration of the MFCC coefficients. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mfcc_accel_men[1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(69, 37)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compute word embeddings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "embeddings_f = audiovis.encode_sentences(model_f, mfcc_accel_men)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "embeddings_c = audiovis.encode_sentences(model_c, mfcc_men)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compute correlations with MEN judgments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import cosine\n",
      "from scipy.stats import spearmanr\n",
      "def correlation(voc, emb, ratings):\n",
      "    REP = dict(zip(voc, emb))\n",
      "    sim = [ 1-cosine(REP[w1],REP[w2]) for (w1,w2,_) in ratings ]\n",
      "    score = [s for (_,_,s) in ratings]\n",
      "    return spearmanr(score, sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correlation(voc_men, embeddings_c, MEN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "SpearmanrResult(correlation=0.18228255690855338, pvalue=7.9454771670729037e-24)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correlation(voc_men, embeddings_f, MEN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "SpearmanrResult(correlation=0.052302840127719075, pvalue=0.0041633549540002783)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
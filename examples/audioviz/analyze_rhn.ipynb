{
 "metadata": {
  "name": "",
  "signature": "sha256:587085059e35557bdbc4f389a057dde2992ad5f36cb1d1a21b9247fb49a9be6d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Analyzing Recurrent Highway Network version of the audio-visual model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import imaginet.task as task\n",
      "import imaginet.defn.audiovis_rhn as audiovis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5005)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = task.load(\"/home/gchrupala/reimaginet/examples/audioviz/human-mfcc-rhn-flickr8k.zip\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import imaginet.data_provider as dp\n",
      "prov = dp.getDataProvider('flickr8k', root='/home/gchrupala/reimaginet', audio_kind='human.max1K.accel3.ord.mfcc')\n",
      "sent_val = list(prov.iterSentences(split='val'))\n",
      "print sent_val[0]['raw']\n",
      "print sent_val[0]['audio'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the boy laying face down on a skateboard is being pushed along the ground by another boy .\n",
        "(622, 37)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Could not read file /home/gchrupala/reimaginet/data/flickr8k/dataset.ipa.jsonl.gz: IPA transcription not available\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sentence embeddings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [ numpy.asarray(sent['audio'], dtype='float32') for sent in sent_val ]\n",
      "embeddings = audiovis.encode_sentences(model, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "embeddings.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(5000, 1024)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Layer states"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "states = audiovis.layer_states(model, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "states[4000].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(478, 4, 1024)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
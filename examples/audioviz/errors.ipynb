{
 "metadata": {
  "name": "",
  "signature": "sha256:c24c3210793779f0eb632d284d629cfe963549e92b3fd3c4b08f49594b98cc9a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy\n",
      "import imaginet.task as task\n",
      "import imaginet.defn.audiovis_rhn as audiovis\n",
      "import imaginet.defn.visual2_rhn as vis2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import imaginet.vendrov_provider as dp\n",
      "\n",
      "prov = dp.getDataProvider(dataset='coco', root='/home/gchrupala/reimaginet/')\n",
      "sent = list(prov.iterSentences(split='val'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_s = task.load(\"/home/gchrupala/reimaginet/run-rhn-coco-9-resume/model.r.e9.zip\")\n",
      "model_w = task.load(\"/home/gchrupala/reimaginet/run-rhn-coco-word-4/model.r.e14.zip\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_s = json.load(open(\"/home/gchrupala/reimaginet/run-rhn-coco-9-resume/scores.9.json\"))\n",
      "score_w = json.load(open(\"/home/gchrupala/reimaginet/run-rhn-coco-word-4/scores.14.json\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "def extreme(good, worse):\n",
      "    ratio = numpy.array(good['ranks']) / numpy.array(worse['ranks'])\n",
      "    return numpy.argsort(ratio)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for j in extreme(score_w, score_s)[:10]:\n",
      "    print score_w['ranks'][j], \"/\", score_s['ranks'][j], sent[j]['raw']\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 / 2255 an engineer is climbing into the engine compartment\n",
        "1 / 1294 a west highland white terrier dressed in a neon yellow vest pants in the sunshine\n",
        "1 / 987 some large streamers some look like a clown fish\n",
        "2 / 1307 a young foal nuzzling its mother in the nose\n",
        "1 / 601 cow tethered with chain eating hay in outdoor field\n",
        "1 / 529 three men eat lunch together at a convention\n",
        "1 / 523 a black bull carrying items and working as a beast of burden\n",
        "1 / 484 a guy posing with a guitar while making a song\n",
        "2 / 968 church alter with blue and yellow stained glass\n",
        "1 / 431 subway map art cow sculpture on the sidewalk\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for j in extreme(score_s, score_w)[:50]:\n",
      "    print score_w['ranks'][j], \"/\", score_s['ranks'][j], j, sent[j]['raw']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "632 / 1 19021 a food process sitting on a counter that has a mixture in it\n",
        "492 / 1 17931 a yellow and white birtd is in flight\n",
        "898 / 2 20002 an inlaid vase sitting in front of a map\n",
        "3370 / 10 19288 a man with a pony tail and bread sitting down\n",
        "279 / 1 12234 there are people loitering in between train cars\n",
        "470 / 2 9544 while in the immediate foreground juts a gnarled tree branch the majority of the view consists of a an expanse of short grass dotted with a few longer tufts and a number of scattered grazing sheep\n",
        "141 / 1 11564 a woman standing in the middle of a farmer marked\n",
        "4344 / 34 5214 a cat with a durham bulls helmet on its head\n",
        "439 / 4 17995 artwork of a ship with three masts and one sail open with a scull and crossbones on it in bluish gray water with gray cement wall in background\n",
        "302 / 3 19318 several japanese colored fans are at different heights\n",
        "190 / 2 10269 a little kid sits on a horse while playing with a lasso\n",
        "734 / 8 12644 the organizer is sitting next to the computer screen\n",
        "624 / 7 12713 this is a streeet sign at an intersection\n",
        "3294 / 37 10684 a couple of bathtubs are leaning against each other\n",
        "174 / 2 14538 a simplistic industrial restroom with all ones necessities\n",
        "2036 / 24 17264 an abandoned bus on the sid eof the rode\n",
        "76 / 1 22663 tennis player trying to reach tennis ball while other player watches from other side of net\n",
        "301 / 4 14181 two young boys gnaw on large orange carrots\n",
        "446 / 6 23409 an old adobe mission with a clock tower stands behind a sparsely leaved tree\n",
        "61 / 1 10991 to scears going up a steep side of a mountain together\n",
        "913 / 16 14890 a blue and black ray holding sandwich coffee and liquor bottles\n",
        "282 / 5 16327 not the biggest workspace in the world but it works\n",
        "3413 / 62 12257 there is no photo here to provide a caption for\n",
        "688 / 13 18705 various equine (horses and zebras) inside stalls under a tent\n",
        "101 / 2 7776 a short train traveling through a rustic contryside\n",
        "48 / 1 7623 a pitcher filled with yellow tulips on a black and white background\n",
        "47 / 1 22841 a man attaches a screen on a toilet seat\n",
        "45 / 1 12587 a tray of yellow swirl cookies with toothpicks sits on a table\n",
        "45 / 1 1148 the young man is setting in the floor with his computer ear an outlet\n",
        "90 / 2 9080 a man sitting on a bench next to a star wars storm trooper\n",
        "43 / 1 22554 a half of a pizza with pepperonis next to a coffee cup\n",
        "42 / 1 605 two men standing on a very tall clock tower with a white clock and two thermometers\n",
        "124 / 3 12649 these two riders are far ahead of the ones behind them\n",
        "2553 / 62 15761 an empty noodle packed with chopped up scallions on it\n",
        "41 / 1 3535 men are taking pictures of a skater grinding on a car\n",
        "40 / 1 11426 a woman with a baby in a stroller near a river\n",
        "306 / 8 3653 a living room decorated with many loud patterns\n",
        "38 / 1 23269 a big pan with three piazzas on it\n",
        "35 / 1 10352 the young boy is setting down on his skateboard\n",
        "69 / 2 142 a freeway sign states las vegas north in the background behind a yellow and blue fire hydrant\n",
        "69 / 2 728 a giraffe is standing near the water with a lot of sailboats lined up\n",
        "34 / 1 18313 a nice refrigerated micro wave combo on a wall\n",
        "102 / 3 22158 a man with his eyes closed sits on a toilet with a blue doll placed on his crotch\n",
        "135 / 4 19247 a mouse kept just besides a cats tail\n",
        "160 / 5 9586 a lady dressed as a cow girl is parading down a street holding a flag\n",
        "319 / 10 9460 a persons reflection is shown in the bathroom mirror they are photographing\n",
        "4494 / 142 10253 some people playing with a disc in a grassy field\n",
        "31 / 1 1048 a black and white photograph of a person that is in rushing waters\n",
        "31 / 1 719 a commercial jet with its wheels down in a blue sky\n",
        "91 / 3 23346 a messy desk with a computer cups glasses bottles books on the desk and the floor\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extreme(score_w, score_s)[-10:],extreme(score_s, score_w)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 179,
       "text": [
        "(array([19318, 17995,  5214, 11564,  9544, 12234, 19288, 20002, 17931, 19021]),\n",
        " array([19021, 17931, 20002, 19288, 12234,  9544, 11564,  5214, 17995, 19318]))"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "vocab = Counter((word for s in prov.iterSentences(split='train') for word in s['tokens']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set_s = set(word for j in extreme(score_s, score_w)[:100] for word in sent[j]['tokens'])\n",
      "set_w = set(word for j in extreme(score_w, score_s)[:100] for word in sent[j]['tokens'])\n",
      "print numpy.sum([1 for word in set_s if vocab[word] < 5])\n",
      "print numpy.sum([1 for word in set_w if vocab[word] < 5])\n",
      "print [word for word in set_s if vocab[word] < 5]\n",
      "print [word for word in set_w if vocab[word] < 5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "28\n",
        "16\n",
        "['piazzas', 'brooms', 'leaved', 'durham', 'sid', 'contryside', 'scull', 'zebras)', '(horses', 'thermometers', 'equine', 'loud', 'streeet', 'immediate', 'majority', 'gnaw', 'simplistic', 'inlaid', 'tufts', 'restricted', 'severe', 'scears', 'gnarled', 'birtd', 'humorously', 'bathtubs', 'attaches', 'devise']\n",
        "['smies', 'whilst', 'tore', 'cairn', 'pubs', 'nutrition', 'macaw', '1929', 'goodmayes', 'chances', 'april', 'highland', 'pictogram', 'minds', 'hampster', 'burden']\n"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for s in prov.iterSentences(split='train'):\n",
      "    if 'streeet' in s['tokens']:\n",
      "        print s['raw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "traffic is traveling both ways on the busy streeet\n",
        "a bus is travling down a non crowded streeet"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "two trucks are parked side by side on the streeet"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "a streeet with buses and other vehicles and stop lights"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extreme_stats(good, worse, N=100):\n",
      "    J = extreme(good, worse)[:N]\n",
      "    L = [len(sent[j]['tokens']) for j in J]\n",
      "    R = [good['ranks'][j] / worse['ranks'][j] for j in J]\n",
      "    return (L, R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Lw,Rw = extreme_stats(score_w, score_s)\n",
      "Ls,Rs = extreme_stats(score_s, score_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.max(Lw), numpy.max(Ls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "(16, 47)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.mean(Rw), numpy.mean(Rs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "(0.0072925481796025475, 0.030546706215076193)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame(dict(Length=numpy.hstack([Lw,Ls]), better=numpy.hstack([numpy.repeat(\"text\",100), numpy.repeat(\"speech\",100)])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"error-length.txt\",\"w\") as f:\n",
      "    f.write(data.to_csv(index=False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images = list(prov.iterImages(split='val'))\n",
      "from imaginet.evaluate import Cdist\n",
      "from imaginet.simple_data import words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def retrieve(model, query, images, config):\n",
      "        task = model.task\n",
      "        scaler = model.scaler\n",
      "        batcher = model.batcher\n",
      "        mapper = batcher.mapper\n",
      "        sents = [ query ] \n",
      "        sents_tok =  [ config['tokenize'](query) ]\n",
      "        predictions = config['encode_sentences'](model, sents_tok, batch_size=32)\n",
      "        img_fs = task.encode_images([ img['feat'] for img in images ])\n",
      "        correct_img = numpy.array([ [ sents[i]['imgid']==images[j]['imgid']\n",
      "                                      for j in range(len(images)) ]\n",
      "                                    for i in range(len(sents)) ] )\n",
      "        distances = Cdist(batch_size=2**13)(predictions, img_fs)\n",
      "        row = distances[0]\n",
      "        ranked = numpy.argsort(row)\n",
      "        return ranked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coco = json.load(open(\"/home/gchrupala/reimaginet/data/coco/dataset.json\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "COCOID = {}\n",
      "\n",
      "for img in coco['images']:\n",
      "    COCOID[img['imgid']]=img['cocoid']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "from IPython.core.display import HTML \n",
      "\n",
      "def display(imgid):\n",
      "    return Image(url='http://mscoco.org/images/%d'%(COCOID[images2[imgid]['imgid']]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def audio(query):\n",
      "    return query['audio']\n",
      "r_w = retrieve(model_w, sent[17931], images, dict(encode_sentences=vis2.encode_sentences, tokenize=words))\n",
      "r_s = retrieve(model_s, sent[17931], images, dict(encode_sentences=audiovis.encode_sentences, tokenize=audio))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import imaginet.data_provider as dp2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prov2 = dp2.getDataProvider(dataset='coco', root='/home/gchrupala/reimaginet/', audio_kind=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Could not read file /home/gchrupala/reimaginet/data/coco/dataset.None.npy: audio features not available\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images2 = list(prov2.iterImages(split='val'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images[0]['imgid'], images[0]['sentences'][0]['raw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "(0, 'a child holding a flowered umbrella and petting a yak')"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent[17931]['raw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "'a yellow and white birtd is in flight'"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(r_w[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/515360\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "<IPython.core.display.Image at 0x7fb4dd977710>"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(r_s[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/498381\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "<IPython.core.display.Image at 0x7fb4dd977b90>"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(5):\n",
      "    print images2[r_s[1]]['sentences'][i]['raw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A parrot flying through a tree filled forest.\n",
        "A yellow and white birtd is in flight.\n",
        "A white bird spreads its wings among tree limbs.\n",
        "A bird is jumping off of a branch.\n",
        "A white bird in the air with wings outstretched.\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compare(i,j=0):\n",
      "    r_w = retrieve(model_w, sent[i], images, dict(encode_sentences=vis2.encode_sentences, tokenize=words))\n",
      "    r_s = retrieve(model_s, sent[i], images, dict(encode_sentences=audiovis.encode_sentences, tokenize=audio))\n",
      "    return(sent[i]['raw'], r_s, r_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s, i1, i2 = compare(9544)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 171,
       "text": [
        "'while in the immediate foreground juts a gnarled tree branch the majority of the view consists of a an expanse of short grass dotted with a few longer tufts and a number of scattered grazing sheep'"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(i1[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/115069\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "<IPython.core.display.Image at 0x7fae19a07d10>"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(i2[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/151842\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 176,
       "text": [
        "<IPython.core.display.Image at 0x7fae1996ecd0>"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compare(11564)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 182,
       "text": [
        "('a woman standing in the middle of a farmer marked',\n",
        " array([2312, 1088, 1459, ..., 3935, 3049, 4719]),\n",
        " array([ 188, 1563, 1335, ..., 3982, 3734, 2906]))"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(2312)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/417987\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "<IPython.core.display.Image at 0x7fae1984c4d0>"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(188)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/195862\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "<IPython.core.display.Image at 0x7fae197e0690>"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compare(10991,j=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "('to scears going up a steep side of a mountain together',\n",
        " array([2198,  691, 2193, ...,  858, 3080,  340]),\n",
        " array([ 703, 2193, 1953, ..., 2491,  340, 3114]))"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(2198)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/527447\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "<IPython.core.display.Image at 0x7fae1961fb90>"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(703)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/30504\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "<IPython.core.display.Image at 0x7fae1961fa50>"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(2193)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/322145\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "<IPython.core.display.Image at 0x7fb4df649490>"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(1953)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://mscoco.org/images/437262\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "<IPython.core.display.Image at 0x7fb4de5d9550>"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K20m\n"
     ]
    }
   ],
   "source": [
    "import imaginet.task as task\n",
    "task = reload(task)\n",
    "import funktional.layer as layer\n",
    "from funktional.layer import params\n",
    "import funktional.util as util\n",
    "from funktional.util import autoassign\n",
    "import theano.tensor as T\n",
    "import random\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imaginet.simple_data import *\n",
    "import imaginet.data_provider as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not read file /home/gchrupala/repos/reimaginet/data/flickr8k/dataset.ipa.jsonl.gz: IPA transcription not available\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    numpy.random.seed(seed)\n",
    "prov = dp.getDataProvider('flickr8k', root='/home/gchrupala/repos/reimaginet')\n",
    "data_c = SimpleData(prov, tokenize=characters, min_df=1, scale=True, batch_size=64, shuffle=True, limit=None)\n",
    "data_w = SimpleData(prov, tokenize=words, min_df=10, scale=True, batch_size=64, shuffle=True, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imaginet.corep\n",
    "reload(imaginet.corep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corep = imaginet.corep.Corep(data_c, data_w, 128, 512, 512, 3, 1, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import sys\n",
    "def valid_loss(task, data):\n",
    "        result = []\n",
    "        for item in data.iter_valid_batches():\n",
    "            inp, target_v, _, _ = item\n",
    "            result.append(task.loss_test(inp, target_v))\n",
    "        return result\n",
    "\n",
    "things = [(\"word\", (corep.data_w, corep.Task_w, Counter())),\n",
    "          (\"char\", (corep.data_c, corep.Task_c, Counter())) ]\n",
    "for epoch in range(1,3):\n",
    "    for name, thing in things:\n",
    "        data, task, costs = thing\n",
    "        for _j, item in enumerate(data_c.iter_train_batches()):\n",
    "                j = _j + 1\n",
    "                inp, target_v, _, _ = item\n",
    "                cost = task.train(inp, target_v)\n",
    "                costs.update(Counter({'cost':cost, 'N':1}))\n",
    "                if j % 10 == 0:\n",
    "                    print epoch, name, j, j*data.batch_size, \"train\", \"\".join([str(costs['cost']/costs['N'])])\n",
    "                    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "things[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "things[1][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corep.save(\"/tmp/corep.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'imaginet.defn.visual' from '/exp2/gchrupala/repos/reimaginet/imaginet/defn/visual.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imaginet.defn.visual\n",
    "reload(imaginet.defn.visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = imaginet.defn.visual.VisualModel(data_c, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<imaginet.defn.visual.VisualModel instance at 0x7fb208be4ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visual',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " 'config',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'depth',\n",
       " 'lr',\n",
       " 'max_norm',\n",
       " 'params',\n",
       " 'save',\n",
       " 'size',\n",
       " 'size_embed',\n",
       " 'size_target',\n",
       " 'weights']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 phoneme 10 640 train 0.748108720779\n",
      "1 phoneme 20 1280 train 0.750677633286\n",
      "1 phoneme 30 1920 train 0.752432314555\n",
      "1 phoneme 40 2560 train 0.752964878082\n",
      "1 phoneme 50 3200 train 0.752103118896\n",
      "1 phoneme 60 3840 train 0.753414471944\n",
      "1 phoneme 70 4480 train 0.754182924543\n",
      "1 phoneme 80 5120 train 0.754847860336\n",
      "1 phoneme 90 5760 train 0.755607520209\n",
      "1 phoneme 100 6400 train 0.756101379395\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import sys\n",
    "for epoch in range(1,5):\n",
    "    costs = Counter()\n",
    "    name = \"phoneme\"\n",
    "    data = model.dataset\n",
    "    task = model.Visual\n",
    "    for _j, item in enumerate(data_c.iter_train_batches()):\n",
    "                j = _j + 1\n",
    "                inp, target_v, _, _ = item\n",
    "                cost = task.train(inp, target_v)\n",
    "                costs.update(Counter({'cost':cost, 'N':1}))\n",
    "                if j % 10 == 0:\n",
    "                    print epoch, name, j, j*data.batch_size, \"train\", \"\".join([str(costs['cost']/costs['N'])])\n",
    "                    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
